{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set is (1443287, 93)\n",
      "Size of the validation set is (60137, 93)\n"
     ]
    }
   ],
   "source": [
    "path='E:\\\\kaggle\\\\Avito Demand Prediction Challenge\\\\features\\\\dataset\\\\'\n",
    "train=pd.read_csv(path+'trainx.csv',header=0)\n",
    "train.drop(['item_id','user_id','title','description'], axis=1, inplace=True )\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "skf = KFold(n_splits = 25, shuffle=True,random_state=123456789)\n",
    "count=0\n",
    "#seed=np.random.randint(0,10)\n",
    "seed=13\n",
    "for train_idx, test_idx in skf.split(train, train.deal_probability):\n",
    "    if count==seed:\n",
    "        train_id=train_idx\n",
    "        test_id=test_idx\n",
    "    count=count+1\n",
    "    \n",
    "train_x, valid_x = train.ix[train_id], train.ix[test_id]\n",
    "del train\n",
    "gc.collect()\n",
    "\n",
    "train_y = train_x['deal_probability']\n",
    "train_x.drop(['deal_probability'], axis=1, inplace=True )\n",
    "print('Size of the training set is {}'.format(train_x.shape))\n",
    "\n",
    "valid_y = valid_x['deal_probability']\n",
    "valid_x.drop(['deal_probability'], axis=1, inplace=True )\n",
    "print('Size of the validation set is {}'.format(valid_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\lightgbm\\basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "H:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\lightgbm\\basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\ttrain's rmse: 0.256989\tvalid's rmse: 0.255614\n",
      "[100]\ttrain's rmse: 0.254066\tvalid's rmse: 0.252947\n",
      "[150]\ttrain's rmse: 0.251319\tvalid's rmse: 0.250468\n",
      "[200]\ttrain's rmse: 0.248762\tvalid's rmse: 0.248177\n",
      "[250]\ttrain's rmse: 0.24636\tvalid's rmse: 0.246047\n",
      "[300]\ttrain's rmse: 0.244107\tvalid's rmse: 0.244072\n",
      "[350]\ttrain's rmse: 0.24201\tvalid's rmse: 0.242254\n",
      "[400]\ttrain's rmse: 0.240033\tvalid's rmse: 0.240555\n",
      "[450]\ttrain's rmse: 0.238191\tvalid's rmse: 0.238992\n",
      "[500]\ttrain's rmse: 0.236456\tvalid's rmse: 0.237543\n",
      "[550]\ttrain's rmse: 0.234823\tvalid's rmse: 0.236193\n",
      "[600]\ttrain's rmse: 0.233304\tvalid's rmse: 0.234949\n",
      "[650]\ttrain's rmse: 0.231888\tvalid's rmse: 0.233821\n",
      "[700]\ttrain's rmse: 0.230558\tvalid's rmse: 0.232767\n",
      "[750]\ttrain's rmse: 0.22931\tvalid's rmse: 0.231796\n",
      "[800]\ttrain's rmse: 0.228112\tvalid's rmse: 0.230878\n",
      "[850]\ttrain's rmse: 0.226997\tvalid's rmse: 0.230037\n",
      "[900]\ttrain's rmse: 0.225941\tvalid's rmse: 0.229256\n",
      "[950]\ttrain's rmse: 0.224947\tvalid's rmse: 0.228541\n",
      "[1000]\ttrain's rmse: 0.223995\tvalid's rmse: 0.227863\n",
      "[1050]\ttrain's rmse: 0.223113\tvalid's rmse: 0.227249\n",
      "[1100]\ttrain's rmse: 0.222247\tvalid's rmse: 0.226655\n",
      "[1150]\ttrain's rmse: 0.221439\tvalid's rmse: 0.226115\n",
      "[1200]\ttrain's rmse: 0.220673\tvalid's rmse: 0.225618\n",
      "[1250]\ttrain's rmse: 0.219931\tvalid's rmse: 0.225161\n",
      "[1300]\ttrain's rmse: 0.21923\tvalid's rmse: 0.224733\n",
      "[1350]\ttrain's rmse: 0.218575\tvalid's rmse: 0.224346\n",
      "[1400]\ttrain's rmse: 0.217942\tvalid's rmse: 0.223977\n",
      "[1450]\ttrain's rmse: 0.217325\tvalid's rmse: 0.223634\n",
      "[1500]\ttrain's rmse: 0.21673\tvalid's rmse: 0.223309\n",
      "[1550]\ttrain's rmse: 0.216147\tvalid's rmse: 0.223001\n",
      "[1600]\ttrain's rmse: 0.215591\tvalid's rmse: 0.222715\n",
      "[1650]\ttrain's rmse: 0.215064\tvalid's rmse: 0.222444\n",
      "[1700]\ttrain's rmse: 0.214544\tvalid's rmse: 0.222198\n",
      "[1750]\ttrain's rmse: 0.214049\tvalid's rmse: 0.221955\n",
      "[1800]\ttrain's rmse: 0.213574\tvalid's rmse: 0.221735\n",
      "[1850]\ttrain's rmse: 0.213106\tvalid's rmse: 0.221529\n",
      "[1900]\ttrain's rmse: 0.212649\tvalid's rmse: 0.221333\n",
      "[1950]\ttrain's rmse: 0.212223\tvalid's rmse: 0.221149\n",
      "[2000]\ttrain's rmse: 0.211813\tvalid's rmse: 0.220981\n",
      "[2050]\ttrain's rmse: 0.211386\tvalid's rmse: 0.220813\n",
      "[2100]\ttrain's rmse: 0.210975\tvalid's rmse: 0.220655\n",
      "[2150]\ttrain's rmse: 0.210565\tvalid's rmse: 0.220502\n",
      "[2200]\ttrain's rmse: 0.21017\tvalid's rmse: 0.220357\n",
      "[2250]\ttrain's rmse: 0.209785\tvalid's rmse: 0.22022\n",
      "[2300]\ttrain's rmse: 0.209399\tvalid's rmse: 0.220084\n",
      "[2350]\ttrain's rmse: 0.209031\tvalid's rmse: 0.219961\n",
      "[2400]\ttrain's rmse: 0.208657\tvalid's rmse: 0.219842\n",
      "[2450]\ttrain's rmse: 0.208294\tvalid's rmse: 0.219726\n",
      "[2500]\ttrain's rmse: 0.207944\tvalid's rmse: 0.219614\n",
      "[2550]\ttrain's rmse: 0.207611\tvalid's rmse: 0.219512\n",
      "[2600]\ttrain's rmse: 0.207258\tvalid's rmse: 0.219412\n",
      "[2650]\ttrain's rmse: 0.206911\tvalid's rmse: 0.219312\n",
      "[2700]\ttrain's rmse: 0.206573\tvalid's rmse: 0.219222\n",
      "[2750]\ttrain's rmse: 0.206236\tvalid's rmse: 0.219137\n",
      "[2800]\ttrain's rmse: 0.205912\tvalid's rmse: 0.219047\n",
      "[2850]\ttrain's rmse: 0.205591\tvalid's rmse: 0.21897\n",
      "[2900]\ttrain's rmse: 0.205265\tvalid's rmse: 0.218889\n",
      "[2950]\ttrain's rmse: 0.204946\tvalid's rmse: 0.218811\n",
      "[3000]\ttrain's rmse: 0.204609\tvalid's rmse: 0.218728\n",
      "[3050]\ttrain's rmse: 0.204286\tvalid's rmse: 0.218648\n",
      "[3100]\ttrain's rmse: 0.203971\tvalid's rmse: 0.218571\n",
      "[3150]\ttrain's rmse: 0.203662\tvalid's rmse: 0.218501\n",
      "[3200]\ttrain's rmse: 0.203364\tvalid's rmse: 0.218437\n",
      "[3250]\ttrain's rmse: 0.203062\tvalid's rmse: 0.218368\n",
      "[3300]\ttrain's rmse: 0.202765\tvalid's rmse: 0.218308\n",
      "[3350]\ttrain's rmse: 0.202463\tvalid's rmse: 0.218248\n",
      "[3400]\ttrain's rmse: 0.202152\tvalid's rmse: 0.21818\n",
      "[3450]\ttrain's rmse: 0.201849\tvalid's rmse: 0.218118\n",
      "[3500]\ttrain's rmse: 0.201563\tvalid's rmse: 0.218067\n",
      "[3550]\ttrain's rmse: 0.201279\tvalid's rmse: 0.218015\n",
      "[3600]\ttrain's rmse: 0.200977\tvalid's rmse: 0.217959\n",
      "[3650]\ttrain's rmse: 0.200685\tvalid's rmse: 0.217908\n",
      "[3700]\ttrain's rmse: 0.200389\tvalid's rmse: 0.217857\n",
      "[3750]\ttrain's rmse: 0.200097\tvalid's rmse: 0.217807\n",
      "[3800]\ttrain's rmse: 0.199812\tvalid's rmse: 0.217763\n",
      "[3850]\ttrain's rmse: 0.199529\tvalid's rmse: 0.217716\n",
      "[3900]\ttrain's rmse: 0.19924\tvalid's rmse: 0.217672\n",
      "[3950]\ttrain's rmse: 0.198971\tvalid's rmse: 0.217633\n",
      "[4000]\ttrain's rmse: 0.198695\tvalid's rmse: 0.217589\n",
      "[4050]\ttrain's rmse: 0.198422\tvalid's rmse: 0.21755\n",
      "[4100]\ttrain's rmse: 0.198147\tvalid's rmse: 0.217509\n",
      "[4150]\ttrain's rmse: 0.197867\tvalid's rmse: 0.217467\n",
      "[4200]\ttrain's rmse: 0.19759\tvalid's rmse: 0.217426\n",
      "[4250]\ttrain's rmse: 0.197322\tvalid's rmse: 0.21739\n",
      "[4300]\ttrain's rmse: 0.197056\tvalid's rmse: 0.217357\n",
      "[4350]\ttrain's rmse: 0.196794\tvalid's rmse: 0.217325\n",
      "[4400]\ttrain's rmse: 0.196533\tvalid's rmse: 0.217287\n",
      "[4450]\ttrain's rmse: 0.196282\tvalid's rmse: 0.217255\n",
      "[4500]\ttrain's rmse: 0.196003\tvalid's rmse: 0.217221\n",
      "[4550]\ttrain's rmse: 0.195755\tvalid's rmse: 0.21719\n",
      "[4600]\ttrain's rmse: 0.195496\tvalid's rmse: 0.21716\n",
      "[4650]\ttrain's rmse: 0.195237\tvalid's rmse: 0.217127\n",
      "[4700]\ttrain's rmse: 0.194983\tvalid's rmse: 0.217096\n",
      "[4750]\ttrain's rmse: 0.194728\tvalid's rmse: 0.217067\n",
      "[4800]\ttrain's rmse: 0.194466\tvalid's rmse: 0.21704\n",
      "[4850]\ttrain's rmse: 0.194204\tvalid's rmse: 0.217017\n",
      "[4900]\ttrain's rmse: 0.193945\tvalid's rmse: 0.216987\n",
      "[4950]\ttrain's rmse: 0.19369\tvalid's rmse: 0.21696\n",
      "[5000]\ttrain's rmse: 0.193442\tvalid's rmse: 0.216938\n",
      "[5050]\ttrain's rmse: 0.193191\tvalid's rmse: 0.216912\n",
      "[5100]\ttrain's rmse: 0.192932\tvalid's rmse: 0.216887\n",
      "[5150]\ttrain's rmse: 0.192684\tvalid's rmse: 0.216864\n",
      "[5200]\ttrain's rmse: 0.192448\tvalid's rmse: 0.21684\n",
      "[5250]\ttrain's rmse: 0.192202\tvalid's rmse: 0.216818\n",
      "[5300]\ttrain's rmse: 0.191962\tvalid's rmse: 0.216796\n",
      "[5350]\ttrain's rmse: 0.191716\tvalid's rmse: 0.21677\n",
      "[5400]\ttrain's rmse: 0.191476\tvalid's rmse: 0.216749\n",
      "[5450]\ttrain's rmse: 0.19124\tvalid's rmse: 0.216729\n",
      "[5500]\ttrain's rmse: 0.190998\tvalid's rmse: 0.216706\n",
      "[5550]\ttrain's rmse: 0.190758\tvalid's rmse: 0.216686\n",
      "[5600]\ttrain's rmse: 0.190515\tvalid's rmse: 0.216662\n",
      "[5650]\ttrain's rmse: 0.190272\tvalid's rmse: 0.216643\n",
      "[5700]\ttrain's rmse: 0.190024\tvalid's rmse: 0.216615\n",
      "[5750]\ttrain's rmse: 0.189782\tvalid's rmse: 0.216594\n",
      "[5800]\ttrain's rmse: 0.189551\tvalid's rmse: 0.216575\n",
      "[5850]\ttrain's rmse: 0.189326\tvalid's rmse: 0.216553\n",
      "[5900]\ttrain's rmse: 0.189087\tvalid's rmse: 0.216534\n",
      "[5950]\ttrain's rmse: 0.188853\tvalid's rmse: 0.216514\n",
      "[6000]\ttrain's rmse: 0.18862\tvalid's rmse: 0.216497\n",
      "[6050]\ttrain's rmse: 0.18839\tvalid's rmse: 0.21648\n",
      "[6100]\ttrain's rmse: 0.188159\tvalid's rmse: 0.216462\n",
      "[6150]\ttrain's rmse: 0.187934\tvalid's rmse: 0.216444\n",
      "[6200]\ttrain's rmse: 0.187703\tvalid's rmse: 0.216428\n",
      "[6250]\ttrain's rmse: 0.187477\tvalid's rmse: 0.216416\n",
      "[6300]\ttrain's rmse: 0.187249\tvalid's rmse: 0.216403\n",
      "[6350]\ttrain's rmse: 0.187024\tvalid's rmse: 0.216389\n",
      "[6400]\ttrain's rmse: 0.1868\tvalid's rmse: 0.216375\n",
      "[6450]\ttrain's rmse: 0.186589\tvalid's rmse: 0.216361\n",
      "[6500]\ttrain's rmse: 0.186366\tvalid's rmse: 0.216345\n",
      "[6550]\ttrain's rmse: 0.186146\tvalid's rmse: 0.216332\n",
      "[6600]\ttrain's rmse: 0.185922\tvalid's rmse: 0.216314\n",
      "[6650]\ttrain's rmse: 0.185706\tvalid's rmse: 0.216301\n",
      "[6700]\ttrain's rmse: 0.185492\tvalid's rmse: 0.216285\n",
      "[6750]\ttrain's rmse: 0.185277\tvalid's rmse: 0.216271\n",
      "[6800]\ttrain's rmse: 0.185058\tvalid's rmse: 0.21626\n",
      "[6850]\ttrain's rmse: 0.184845\tvalid's rmse: 0.216248\n",
      "[6900]\ttrain's rmse: 0.184635\tvalid's rmse: 0.216233\n",
      "[6950]\ttrain's rmse: 0.184423\tvalid's rmse: 0.216222\n",
      "[7000]\ttrain's rmse: 0.184212\tvalid's rmse: 0.21621\n",
      "[7050]\ttrain's rmse: 0.184001\tvalid's rmse: 0.216198\n",
      "[7100]\ttrain's rmse: 0.183784\tvalid's rmse: 0.216186\n",
      "[7150]\ttrain's rmse: 0.183575\tvalid's rmse: 0.216174\n",
      "[7200]\ttrain's rmse: 0.183361\tvalid's rmse: 0.216165\n",
      "[7250]\ttrain's rmse: 0.183157\tvalid's rmse: 0.216154\n",
      "[7300]\ttrain's rmse: 0.182947\tvalid's rmse: 0.216144\n",
      "[7350]\ttrain's rmse: 0.182733\tvalid's rmse: 0.216133\n",
      "[7400]\ttrain's rmse: 0.18253\tvalid's rmse: 0.216126\n",
      "[7450]\ttrain's rmse: 0.182324\tvalid's rmse: 0.216115\n",
      "[7500]\ttrain's rmse: 0.18212\tvalid's rmse: 0.216105\n",
      "[7550]\ttrain's rmse: 0.181918\tvalid's rmse: 0.216096\n",
      "[7600]\ttrain's rmse: 0.181721\tvalid's rmse: 0.216088\n",
      "[7650]\ttrain's rmse: 0.181522\tvalid's rmse: 0.216077\n",
      "[7700]\ttrain's rmse: 0.181323\tvalid's rmse: 0.216067\n",
      "[7750]\ttrain's rmse: 0.181127\tvalid's rmse: 0.216057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7800]\ttrain's rmse: 0.180925\tvalid's rmse: 0.216048\n",
      "[7850]\ttrain's rmse: 0.180725\tvalid's rmse: 0.21604\n",
      "[7900]\ttrain's rmse: 0.180524\tvalid's rmse: 0.216031\n",
      "[7950]\ttrain's rmse: 0.180329\tvalid's rmse: 0.216021\n",
      "[8000]\ttrain's rmse: 0.180129\tvalid's rmse: 0.216014\n",
      "[8050]\ttrain's rmse: 0.179936\tvalid's rmse: 0.216007\n",
      "[8100]\ttrain's rmse: 0.179742\tvalid's rmse: 0.215999\n",
      "[8150]\ttrain's rmse: 0.179547\tvalid's rmse: 0.21599\n",
      "[8200]\ttrain's rmse: 0.179349\tvalid's rmse: 0.215982\n",
      "[8250]\ttrain's rmse: 0.179155\tvalid's rmse: 0.215976\n",
      "[8300]\ttrain's rmse: 0.178969\tvalid's rmse: 0.215967\n",
      "[8350]\ttrain's rmse: 0.178785\tvalid's rmse: 0.215958\n",
      "[8400]\ttrain's rmse: 0.178601\tvalid's rmse: 0.215951\n",
      "[8450]\ttrain's rmse: 0.178414\tvalid's rmse: 0.215945\n",
      "[8500]\ttrain's rmse: 0.178223\tvalid's rmse: 0.215937\n",
      "[8550]\ttrain's rmse: 0.178034\tvalid's rmse: 0.215931\n",
      "[8600]\ttrain's rmse: 0.177846\tvalid's rmse: 0.215924\n",
      "[8650]\ttrain's rmse: 0.177658\tvalid's rmse: 0.215918\n",
      "[8700]\ttrain's rmse: 0.177469\tvalid's rmse: 0.21591\n",
      "[8750]\ttrain's rmse: 0.17728\tvalid's rmse: 0.215901\n",
      "[8800]\ttrain's rmse: 0.177094\tvalid's rmse: 0.215896\n",
      "[8850]\ttrain's rmse: 0.176908\tvalid's rmse: 0.215893\n",
      "[8900]\ttrain's rmse: 0.176724\tvalid's rmse: 0.215886\n",
      "[8950]\ttrain's rmse: 0.176544\tvalid's rmse: 0.215881\n",
      "[9000]\ttrain's rmse: 0.176359\tvalid's rmse: 0.215873\n",
      "[9050]\ttrain's rmse: 0.176176\tvalid's rmse: 0.215868\n",
      "[9100]\ttrain's rmse: 0.175995\tvalid's rmse: 0.21586\n",
      "[9150]\ttrain's rmse: 0.175809\tvalid's rmse: 0.215855\n",
      "[9200]\ttrain's rmse: 0.175625\tvalid's rmse: 0.21585\n",
      "[9250]\ttrain's rmse: 0.175451\tvalid's rmse: 0.215844\n",
      "[9300]\ttrain's rmse: 0.175266\tvalid's rmse: 0.215842\n",
      "[9350]\ttrain's rmse: 0.175084\tvalid's rmse: 0.215838\n",
      "[9400]\ttrain's rmse: 0.174906\tvalid's rmse: 0.215834\n",
      "[9450]\ttrain's rmse: 0.174729\tvalid's rmse: 0.215828\n",
      "[9500]\ttrain's rmse: 0.174546\tvalid's rmse: 0.215824\n",
      "[9550]\ttrain's rmse: 0.174371\tvalid's rmse: 0.21582\n",
      "[9600]\ttrain's rmse: 0.174193\tvalid's rmse: 0.215815\n",
      "[9650]\ttrain's rmse: 0.174018\tvalid's rmse: 0.21581\n",
      "[9700]\ttrain's rmse: 0.173846\tvalid's rmse: 0.215803\n",
      "[9750]\ttrain's rmse: 0.173677\tvalid's rmse: 0.215798\n",
      "[9800]\ttrain's rmse: 0.173502\tvalid's rmse: 0.215795\n",
      "[9850]\ttrain's rmse: 0.173324\tvalid's rmse: 0.215788\n",
      "[9900]\ttrain's rmse: 0.173147\tvalid's rmse: 0.215784\n",
      "[9950]\ttrain's rmse: 0.172973\tvalid's rmse: 0.215778\n",
      "[10000]\ttrain's rmse: 0.172799\tvalid's rmse: 0.215774\n",
      "[10050]\ttrain's rmse: 0.172627\tvalid's rmse: 0.215768\n",
      "[10100]\ttrain's rmse: 0.172458\tvalid's rmse: 0.215766\n",
      "[10150]\ttrain's rmse: 0.172281\tvalid's rmse: 0.215763\n",
      "[10200]\ttrain's rmse: 0.172104\tvalid's rmse: 0.215758\n",
      "[10250]\ttrain's rmse: 0.171934\tvalid's rmse: 0.215753\n",
      "[10300]\ttrain's rmse: 0.171763\tvalid's rmse: 0.21575\n",
      "[10350]\ttrain's rmse: 0.171586\tvalid's rmse: 0.215747\n",
      "[10400]\ttrain's rmse: 0.171414\tvalid's rmse: 0.215743\n",
      "[10450]\ttrain's rmse: 0.171251\tvalid's rmse: 0.215742\n",
      "[10500]\ttrain's rmse: 0.171084\tvalid's rmse: 0.215739\n",
      "[10550]\ttrain's rmse: 0.170915\tvalid's rmse: 0.215735\n",
      "[10600]\ttrain's rmse: 0.170744\tvalid's rmse: 0.215731\n",
      "[10650]\ttrain's rmse: 0.170572\tvalid's rmse: 0.215728\n",
      "[10700]\ttrain's rmse: 0.170401\tvalid's rmse: 0.215725\n",
      "[10750]\ttrain's rmse: 0.170233\tvalid's rmse: 0.215723\n",
      "[10800]\ttrain's rmse: 0.170066\tvalid's rmse: 0.215717\n",
      "[10850]\ttrain's rmse: 0.169896\tvalid's rmse: 0.215714\n",
      "[10900]\ttrain's rmse: 0.169735\tvalid's rmse: 0.215708\n",
      "[10950]\ttrain's rmse: 0.169575\tvalid's rmse: 0.215704\n",
      "[11000]\ttrain's rmse: 0.169411\tvalid's rmse: 0.215701\n",
      "[11050]\ttrain's rmse: 0.169246\tvalid's rmse: 0.2157\n",
      "[11100]\ttrain's rmse: 0.169083\tvalid's rmse: 0.215696\n",
      "[11150]\ttrain's rmse: 0.168922\tvalid's rmse: 0.215693\n",
      "[11200]\ttrain's rmse: 0.168752\tvalid's rmse: 0.21569\n",
      "[11250]\ttrain's rmse: 0.168591\tvalid's rmse: 0.215687\n",
      "[11300]\ttrain's rmse: 0.168428\tvalid's rmse: 0.215683\n",
      "[11350]\ttrain's rmse: 0.168269\tvalid's rmse: 0.215681\n",
      "[11400]\ttrain's rmse: 0.168116\tvalid's rmse: 0.215678\n",
      "[11450]\ttrain's rmse: 0.167952\tvalid's rmse: 0.215676\n",
      "[11500]\ttrain's rmse: 0.167788\tvalid's rmse: 0.215674\n",
      "[11550]\ttrain's rmse: 0.167626\tvalid's rmse: 0.215672\n",
      "[11600]\ttrain's rmse: 0.167466\tvalid's rmse: 0.215669\n",
      "[11650]\ttrain's rmse: 0.167305\tvalid's rmse: 0.215666\n",
      "[11700]\ttrain's rmse: 0.167141\tvalid's rmse: 0.215664\n",
      "[11750]\ttrain's rmse: 0.16698\tvalid's rmse: 0.215661\n",
      "[11800]\ttrain's rmse: 0.166826\tvalid's rmse: 0.215657\n",
      "[11850]\ttrain's rmse: 0.166664\tvalid's rmse: 0.215656\n",
      "[11900]\ttrain's rmse: 0.166505\tvalid's rmse: 0.215652\n",
      "[11950]\ttrain's rmse: 0.166352\tvalid's rmse: 0.215649\n",
      "[12000]\ttrain's rmse: 0.166196\tvalid's rmse: 0.215648\n",
      "[12050]\ttrain's rmse: 0.166035\tvalid's rmse: 0.215645\n",
      "[12100]\ttrain's rmse: 0.165875\tvalid's rmse: 0.215642\n",
      "[12150]\ttrain's rmse: 0.165715\tvalid's rmse: 0.215639\n",
      "[12200]\ttrain's rmse: 0.165558\tvalid's rmse: 0.215637\n",
      "[12250]\ttrain's rmse: 0.165403\tvalid's rmse: 0.215633\n",
      "[12300]\ttrain's rmse: 0.16525\tvalid's rmse: 0.215631\n",
      "[12350]\ttrain's rmse: 0.165098\tvalid's rmse: 0.215629\n",
      "[12400]\ttrain's rmse: 0.164945\tvalid's rmse: 0.215626\n",
      "[12450]\ttrain's rmse: 0.164788\tvalid's rmse: 0.215627\n",
      "[12500]\ttrain's rmse: 0.164629\tvalid's rmse: 0.215623\n",
      "[12550]\ttrain's rmse: 0.164477\tvalid's rmse: 0.215621\n",
      "[12600]\ttrain's rmse: 0.164325\tvalid's rmse: 0.215619\n",
      "[12650]\ttrain's rmse: 0.164178\tvalid's rmse: 0.215617\n",
      "[12700]\ttrain's rmse: 0.164029\tvalid's rmse: 0.215615\n",
      "[12750]\ttrain's rmse: 0.163873\tvalid's rmse: 0.215613\n",
      "[12800]\ttrain's rmse: 0.163723\tvalid's rmse: 0.21561\n",
      "[12850]\ttrain's rmse: 0.163568\tvalid's rmse: 0.21561\n",
      "[12900]\ttrain's rmse: 0.163426\tvalid's rmse: 0.215609\n",
      "[12950]\ttrain's rmse: 0.163272\tvalid's rmse: 0.215607\n",
      "[13000]\ttrain's rmse: 0.163118\tvalid's rmse: 0.215605\n",
      "[13050]\ttrain's rmse: 0.16297\tvalid's rmse: 0.215603\n",
      "[13100]\ttrain's rmse: 0.162825\tvalid's rmse: 0.215599\n",
      "[13150]\ttrain's rmse: 0.162676\tvalid's rmse: 0.215597\n",
      "[13200]\ttrain's rmse: 0.162528\tvalid's rmse: 0.215597\n",
      "[13250]\ttrain's rmse: 0.16238\tvalid's rmse: 0.215595\n",
      "[13300]\ttrain's rmse: 0.162231\tvalid's rmse: 0.215594\n",
      "[13350]\ttrain's rmse: 0.162079\tvalid's rmse: 0.215593\n",
      "[13400]\ttrain's rmse: 0.161937\tvalid's rmse: 0.215591\n",
      "[13450]\ttrain's rmse: 0.16179\tvalid's rmse: 0.215589\n",
      "[13500]\ttrain's rmse: 0.161647\tvalid's rmse: 0.215587\n",
      "[13550]\ttrain's rmse: 0.161499\tvalid's rmse: 0.215587\n",
      "[13600]\ttrain's rmse: 0.161351\tvalid's rmse: 0.215586\n",
      "[13650]\ttrain's rmse: 0.161201\tvalid's rmse: 0.215583\n",
      "[13700]\ttrain's rmse: 0.161056\tvalid's rmse: 0.215581\n",
      "[13750]\ttrain's rmse: 0.160908\tvalid's rmse: 0.21558\n",
      "[13800]\ttrain's rmse: 0.160763\tvalid's rmse: 0.215581\n",
      "[13850]\ttrain's rmse: 0.160618\tvalid's rmse: 0.215581\n",
      "[13900]\ttrain's rmse: 0.160468\tvalid's rmse: 0.21558\n",
      "[13950]\ttrain's rmse: 0.160325\tvalid's rmse: 0.21558\n",
      "[14000]\ttrain's rmse: 0.160184\tvalid's rmse: 0.215578\n",
      "[14050]\ttrain's rmse: 0.160043\tvalid's rmse: 0.215576\n",
      "[14100]\ttrain's rmse: 0.159901\tvalid's rmse: 0.215575\n",
      "[14150]\ttrain's rmse: 0.159757\tvalid's rmse: 0.215574\n",
      "[14200]\ttrain's rmse: 0.159621\tvalid's rmse: 0.215573\n",
      "[14250]\ttrain's rmse: 0.159478\tvalid's rmse: 0.215574\n",
      "[14300]\ttrain's rmse: 0.159335\tvalid's rmse: 0.215573\n",
      "[14350]\ttrain's rmse: 0.159192\tvalid's rmse: 0.21557\n",
      "[14400]\ttrain's rmse: 0.159045\tvalid's rmse: 0.21557\n",
      "[14450]\ttrain's rmse: 0.158904\tvalid's rmse: 0.215569\n",
      "[14500]\ttrain's rmse: 0.158759\tvalid's rmse: 0.215568\n",
      "[14550]\ttrain's rmse: 0.158611\tvalid's rmse: 0.215565\n",
      "[14600]\ttrain's rmse: 0.158465\tvalid's rmse: 0.215565\n",
      "[14650]\ttrain's rmse: 0.158326\tvalid's rmse: 0.215562\n",
      "[14700]\ttrain's rmse: 0.158188\tvalid's rmse: 0.215563\n",
      "[14750]\ttrain's rmse: 0.158048\tvalid's rmse: 0.215563\n",
      "[14800]\ttrain's rmse: 0.157904\tvalid's rmse: 0.215561\n",
      "[14850]\ttrain's rmse: 0.157767\tvalid's rmse: 0.215561\n",
      "[14900]\ttrain's rmse: 0.157628\tvalid's rmse: 0.215561\n",
      "[14950]\ttrain's rmse: 0.157492\tvalid's rmse: 0.215561\n",
      "[15000]\ttrain's rmse: 0.157355\tvalid's rmse: 0.215561\n",
      "[15050]\ttrain's rmse: 0.157217\tvalid's rmse: 0.21556\n",
      "[15100]\ttrain's rmse: 0.157079\tvalid's rmse: 0.215559\n",
      "[15150]\ttrain's rmse: 0.156938\tvalid's rmse: 0.215558\n",
      "[15200]\ttrain's rmse: 0.156802\tvalid's rmse: 0.215556\n",
      "[15250]\ttrain's rmse: 0.156663\tvalid's rmse: 0.215554\n",
      "[15300]\ttrain's rmse: 0.156519\tvalid's rmse: 0.215551\n",
      "[15350]\ttrain's rmse: 0.156386\tvalid's rmse: 0.21555\n",
      "[15400]\ttrain's rmse: 0.156251\tvalid's rmse: 0.21555\n",
      "[15450]\ttrain's rmse: 0.156115\tvalid's rmse: 0.215549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15500]\ttrain's rmse: 0.155978\tvalid's rmse: 0.215548\n",
      "[15550]\ttrain's rmse: 0.155841\tvalid's rmse: 0.215548\n",
      "[15600]\ttrain's rmse: 0.155702\tvalid's rmse: 0.215548\n",
      "[15650]\ttrain's rmse: 0.155565\tvalid's rmse: 0.215549\n",
      "[15700]\ttrain's rmse: 0.155428\tvalid's rmse: 0.215549\n",
      "[15750]\ttrain's rmse: 0.155294\tvalid's rmse: 0.215549\n",
      "Early stopping, best iteration is:\n",
      "[15559]\ttrain's rmse: 0.155815\tvalid's rmse: 0.215547\n"
     ]
    }
   ],
   "source": [
    "predictors = list(train_x.columns)\n",
    "categorical = ['region','city','parent_category_name','category_name', \n",
    "              'user_type','activation_date', 'param_1', 'param123','image_top_1',\n",
    "              'cluster_5', 'cluster_10','cluster_20','item_seq_number']\n",
    "\n",
    "lgb_train = lgb.Dataset(train_x, label=train_y, feature_name=predictors, categorical_feature=categorical)\n",
    "lgb_valid = lgb.Dataset(valid_x, label=valid_y, feature_name=predictors, categorical_feature=categorical)\n",
    "\n",
    "del train_x, train_y, valid_x, valid_y \n",
    "gc.collect()\n",
    "\n",
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'xentropy',\n",
    "        'metric':'rmse',\n",
    "        'learning_rate': 0.001,\n",
    "        #'is_unbalance': 'true',  #because training data is unbalance (replaced with scale_pos_weight)\n",
    "        'num_leaves': 1024,  # we should let it be smaller than 2^(max_depth)\n",
    "        'max_depth': 40, #-1 # -1 means no limit\n",
    "        #'min_data_in_leaf': 10,\n",
    "        'max_bin': 255,  # Number of bucketed bin for feature values\n",
    "        'feature_fraction': 0.5, # 0.5\n",
    "        'bagging_fraction': 0.75, # 0.75\n",
    "        'bagging_freq': 1, #2\n",
    "        'min_split_gain': 0.0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'lambda_l1': 0.0,  # L1 regularization term on weights\n",
    "        'lambda_l2': 0.01,  # L2 regularization term on weights\n",
    "        'nthread': 4,\n",
    "        'verbose': 0,\n",
    "        'is_training_metric': True\n",
    "        #'scale_pos_weight':99\n",
    "    }\n",
    "\n",
    "model_lgb = lgb.train(lgb_params, lgb_train, valid_sets=[lgb_train,lgb_valid], valid_names=['train','valid'],\n",
    "                      num_boost_round=50000, early_stopping_rounds=200, verbose_eval=50)\n",
    "#model_lgb.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.save_model('modelxsssss.txt')\n",
    "#bst = lgb.Booster(model_file='mode.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='E:\\\\kaggle\\\\Avito Demand Prediction Challenge\\\\features\\\\dataset\\\\'\n",
    "test=pd.read_csv(path+'testx.csv',header=0)\n",
    "item=test['item_id']\n",
    "test.drop(['item_id','user_id','title','description'], axis=1, inplace=True )\n",
    "predictors = list(test.columns)\n",
    "categorical = ['region','city','parent_category_name','category_name', \n",
    "              'user_type','activation_date', 'param_1', 'param123','image_top_1',\n",
    "              'cluster_5', 'cluster_10','cluster_20','item_seq_number']\n",
    "lgb_test = lgb.Dataset(test, feature_name=predictors, categorical_feature=categorical)\n",
    "\n",
    "y_preds=model_lgb.predict(test, num_iteration=model_lgb.best_iteration)\n",
    "\n",
    "result = {'item_id':item, 'deal_probability': y_preds}\n",
    "result = pd.DataFrame(data=result)\n",
    "result=result[['item_id','deal_probability']]\n",
    "result.to_csv('resultsssss.001.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=model_lgb.predict(test, num_iteration=model_lgb.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'item_id':item, 'deal_probability': y_preds}\n",
    "result = pd.DataFrame(data=result)\n",
    "result=result[['item_id','deal_probability']]\n",
    "result.to_csv('result0.001.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05546752, 0.13976673, 0.19719934, ..., 0.04052349, 0.35874685,\n",
       "       0.0004964 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
